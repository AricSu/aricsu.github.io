import{_ as r}from"./chunks/03-DM_Worker_Components.CNbSlk6_.js";import{_ as o,c as t,a5 as c,o as a}from"./chunks/framework.PytyN_aB.js";const g=JSON.parse('{"title":"DM syncer","description":"","frontmatter":{},"headers":[],"relativePath":"zh/tidb/05TiDB-生态工具/5-4DM/05TiDB-DM syncer.md","filePath":"zh/tidb/05TiDB-生态工具/5-4DM/05TiDB-DM syncer.md"}'),n={name:"zh/tidb/05TiDB-生态工具/5-4DM/05TiDB-DM syncer.md"};function l(d,e,i,s,b,p){return a(),t("div",null,e[0]||(e[0]=[c('<h1 id="dm-syncer" tabindex="-1">DM syncer <a class="header-anchor" href="#dm-syncer" aria-label="Permalink to &quot;DM syncer&quot;">​</a></h1><h2 id="what-s-syncer" tabindex="-1">What&#39;s syncer <a class="header-anchor" href="#what-s-syncer" aria-label="Permalink to &quot;What&#39;s syncer&quot;">​</a></h2><ol><li><p>Syncer 可以同步你的 MySQL 数据到另一个 MySQL 数据库，这是 Package 层面的定义，因为 Syncer 真正实现了读取 MySQL Binlog 并转化为 DML/DDL 语句同步到下游的关键逻辑， DM Master 和 Worker 更像是外层高可用性的封装，偏颇的说。</p><figure><img src="'+r+'" alt="DM_Worker_Components" tabindex="0"><figcaption>DM_Worker_Components</figcaption></figure></li></ol><h2 id="pessimist" tabindex="-1">Pessimist <a class="header-anchor" href="#pessimist" aria-label="Permalink to &quot;Pessimist&quot;">​</a></h2><ol><li><p>我已经谈论了一些工人在悲观的DDL机制中所做的事情，PTAL在<a href="./03TiDB-DM Master.html">悲观主义者内容</a>首先在DM Master中。</p></li><li><p>从 DM worker 的 <code>DM Syncer Main Steps</code> 部分，我们可以看到 DM worker 中的 Syncer 只是把他的 DDL Info 上传给 DM Masrter, 如果它是 DDL 锁的 Owner 的话，监视由 DM Master 生成的 Operation 放在 <code>DDL作业队列</code> 中。</p></li></ol><h2 id="optimist" tabindex="-1">Optimist <a class="header-anchor" href="#optimist" aria-label="Permalink to &quot;Optimist&quot;">​</a></h2><ol><li><p>也请看看我写的<a href="./../5-4DM/03TiDB-DM Master.html">这里</a>，所有这些都是因为如果没有预读，你可能会感到困惑。大部分都是相关的。</p></li><li><p>本页顶部的图片，唯一不同的处理步骤只是 <code>GetOperation</code> 之后的 <code>switch op.ConflictStage</code>。他们在etcd 上给出了悲观主义者和乐观主义者完全不同的信息，在乐观主义中把信息交给 DM Master 后，DM Worker 获得并判断是否存在冲突，并以不同的方式处理下一步。在<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/ddl.go#L883" target="_blank" rel="noreferrer">这里</a>调整冲突后，DM Worker 实际得到的是 DM Master 返回的结果。</p></li></ol><h2 id="streamcontroller" tabindex="-1">streamController <a class="header-anchor" href="#streamcontroller" aria-label="Permalink to &quot;streamController&quot;">​</a></h2><ol><li><p>streamController 包括一些字段，如 <code>retryStrategy</code>， <code>syncCfg</code>， <code>fromDB</code> 等，在<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/binlogstream/streamer_controller.go#L131" target="_blank" rel="noreferrer">它的 struct</a> 可以看到更多，主要用于去控制读取 binlog，包括将streamer 重置 binlog 位置或 GTID，读取下一个 binlog 事件，从本地 streamer 传输到远程 streamer（remote or relay）。</p></li><li><p>从<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/binlogstream/streamer_controller.go#L54-L83" target="_blank" rel="noreferrer"><code>GenerateStreamFrom</code></a>和<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/binlogstream/streamer_controller.go#L337" target="_blank" rel="noreferrer"><code>func GetEvent</code></a>的界面可以看到，它连续封装了MySQL Binlog到下一个事件的状态信息。</p></li></ol><h2 id="runningloop" tabindex="-1">RunningLoop <a class="header-anchor" href="#runningloop" aria-label="Permalink to &quot;RunningLoop&quot;">​</a></h2><ol><li><p>实际上，<code>RunnLoop</code> 是我创造的一个名称，它应该是 <code>func (s *Syncer) Run</code>。我更改名称的原因是使其更有意义，因为关键逻辑参考了一个 694行的函数中 <a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L1968-L1969" target="_blank" rel="noreferrer">this for-loop</a>，较为难理解。</p></li><li><p>如图所示，streamController 将通过 <code>handleRotateEvent</code>， <code>HandleQueryEvent</code> 等连续发送 MySQL Binlog 和运行处理每个 Binglog Event。</p></li><li><p>在 <a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L2535" target="_blank" rel="noreferrer">func handleRowsEvent</a>中，MySQL定义了太多的事件，DM只需要转换其中的一部分，如 <code>UPDATE_ROWS_EVENT</code>， <code>DELETE_ROWS_EVENT</code>，<code>WRITE_ROWS_EVENT</code> 等。Syncer 可以通过<a href="https://github.com/go-mysql-org/go-mysql" target="_blank" rel="noreferrer">Package mysql-go</a>和一些 Event 信息做到这一点，你可以在<a href="https://dev.mysql.com/doc/dev/mysql-server/latest/page_protocol_replication_binlog_event.html" target="_blank" rel="noreferrer">page_protocol_replication_binlog_event</a> 查看到更多定义解析。</p></li></ol><h2 id="syncdml" tabindex="-1">syncDML <a class="header-anchor" href="#syncdml" aria-label="Permalink to &quot;syncDML&quot;">​</a></h2><ol><li><p>这个<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L1534" target="_blank" rel="noreferrer">func syncDML</a> 所做的只是从 dmlJobCh 连续获取 dmlJob，并将其输出到压缩器或因果关系。它取决于你是否将 <code>compact</code> 配置为true，这是一个加速复制速度的调优。<a href="https://docs.pingcap.com/zh/tidb/stable/dm-dml-replication-logic#compactor" target="_blank" rel="noreferrer">compact</a> 是一个新功能，用于将一些 DML 压缩为一个 DML，如: <code>INSERT + UPDATE =&gt; INSERT</code>， <code>INSERT + DELETE =&gt; DELETE</code>等。我们都知道，像 <code>insert into XXX values()，()…;</code> 这样的查询比 <code>insert into XXX values();insert into XXX values();…</code> 快很多。</p></li><li><p>同时，<code>Causality</code> 也不容忽视，因为该功能用于检测 DML 冲突，而不仅仅是有序地复制 DML。更多关于因果关系并行算法的信息，在<a href="https://cn.pingcap.com/blog/tidb-binlog-source-code-reading-8#%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8CDML" target="_blank" rel="noreferrer">这个博客</a>，简而言之，每个事件将被 PK 或 UK 分派到不同的 <code>因果关系树</code> 的组中，如果后一个事件的关键字与前一个有冲突。例如冲突可能是 <code>Event-1: INSERT INTO table_name (pk, uk) VALUES(1,2);</code> 和 <code>Event-4: DELETE FROM table_name WHERE pk = 1;</code> 必须按时间顺序执行，反之亦然，将会有冲突。这样 DM 就可以在不同的 <code>因果树</code> 组之间同步并行的执行 DML。因此，如果因果关系检测到任何冲突，必须首先将组中已经存在的查询同步到下游(TiDB集群)。</p></li></ol><h2 id="syncddl" tabindex="-1">syncDDL <a class="header-anchor" href="#syncddl" aria-label="Permalink to &quot;syncDDL&quot;">​</a></h2><ol><li><p>恕我直言，这只是一个 dispath 组件函数，它的目标是 DDL shard 逻辑和记录指标。如果配置为 <code>shard pessimism</code>，</p></li><li><p>在 <a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L1356" target="_blank" rel="noreferrer">func syncDDL</a>中。它将检查 <a href="https://docs.pingcap.com/tidb/stable/dm-shard-merge#configure-parameters" target="_blank" rel="noreferrer">shardMode</a> 的配置模式，以执行完全不同的行为。 对于悲观模式，请查看<a href="#pessimist">同步器中的悲观者组件</a>和<a href="./03TiDB-DM Master.html">DM Masrer Pessmist 组件</a>。而对于乐观主义者，请看<a href="./03TiDB-DM Master.html">DM Masrer Optimist 组件</a>和<a href="#optimist">syncer中的乐观主义者成分</a>。我认为这是整个 DM 中最复杂和最重要的逻辑。</p></li></ol><h2 id="ddlworker" tabindex="-1">DDLWorker <a class="header-anchor" href="#ddlworker" aria-label="Permalink to &quot;DDLWorker&quot;">​</a></h2><ol><li><p>DDLWorker 只是一个组件来做关于 DDL 的工作，也有一些关键功能，如 <code>HandleQueryEvent</code>， <code>skipQueryEvent</code>， <code>processOneDDL</code> 和 <code>handleDDL</code> 的正常 DDL，乐观 DDL 和悲观 DDL。</p></li><li><p>而 <code>HandleQueryEvent</code> 连接了我上面提到的函数。它将记录指标，并负责将一个 SQL 中压缩的多个 DDL 类型拆分为一些单个 DDL。因为，直到现在，TiDB还不支持<a href="https://docs.pingcap.com/tidb/stable/dm-faq#if-a-statement-executed-upstream-contains-multiple-ddl-operations-does-dm-support-such-migration" target="_blank" rel="noreferrer">同时执行多个 DDL</a>。</p></li></ol><h2 id="dmlworker" tabindex="-1">DMLWorker <a class="header-anchor" href="#dmlworker" aria-label="Permalink to &quot;DMLWorker&quot;">​</a></h2><ol><li><p>此外，主要函数是 <code>dmlWorkerWrap</code> ， <code>sendJobToAllDmlQueue</code> ， <code>executeJobs</code> ， <code>gensql</code> 。DM有一个名为<a href="https://docs.pingcap.com/zh/tidb/stable/dm-tune-configuration#worker-count" target="_blank" rel="noreferrer">worker-count</a>的配置参数，可以加速DML复制速度。在 `dmlWorkerWrap &#39;中，该步骤创建了worker-count的数量作为并发来同步dml。DML被 <a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/dml_worker.go#L101" target="_blank" rel="noreferrer">func run</a> 中的<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/dml_worker.go#L138" target="_blank" rel="noreferrer">Hash 每个DML Key</a>分割。这样，每个队列以 <a href="https://docs.pingcap.com/tidb/stable/dm-tune-configuration#batch" target="_blank" rel="noreferrer">DM batch</a>参数的批处理方式执行。简而言之，DMLWorker将作业转换为SQL并将其刷新到下游。</p></li><li><p>你可以在<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/dml_worker.go#L33" target="_blank" rel="noreferrer">这里</a>找到更多细节。</p></li></ol><h2 id="checkpointworker" tabindex="-1">checkpointWorker <a class="header-anchor" href="#checkpointworker" aria-label="Permalink to &quot;checkpointWorker&quot;">​</a></h2><ol><li><p>CheckPoint 表示 Syncer 的检查点状态，包括全局 binlog 的检查点和每个表的检查点，当保存检查点时，我们必须在内存中保存，并将其永久地保存到 DB(或文件)。对于分片合并，在内存中保存检查点，以支持重新同步特殊streamer 时的跳过，但在一个分片组的所有 ddl 被同步和执行之前，不应该永久保存检查点。因为，当重新启动以继续同步时，所有分片 ddl 必须再次尝试同步。这里有一个关键的<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/checkpoint.go#L227" target="_blank" rel="noreferrer">接口</a>，你可以知道它是如何工作的。</p></li><li><p>在 Syncer 中，<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L1187" target="_blank" rel="noreferrer">flushcheckpoint</a>和<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L1223" target="_blank" rel="noreferrer">flushCheckPointsAsync</a>调用 <code>checkpointFlushWorker.Add(task)</code> 将检查点任务推入checkpointWorker。还有一个循环 <a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/checkpoint_flush_worker.go#L91" target="_blank" rel="noreferrer">func Run</a>来分派到同步/异步逻辑中，并使用 FlushPointsExcept 永久地将全局 checkpint 刷新到下游检查点表中。到目前为止，异步刷新检查点还没有发布，更多信息请访问<a href="https://github.com/pingcap/tiflow/blob/master/dm/docs/RFCS/20211012_async_checkpoint_flush.md" target="_blank" rel="noreferrer">RFC</a>。</p></li><li><p>需要刷新检查点的场景有四种。其中一半包含在 <a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L1048" target="_blank" rel="noreferrer">func handleJob</a> 中，另一半包含在 <a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L1654" target="_blank" rel="noreferrer">func Syncer.Run</a> 中。<br> a. <strong>DDL执行</strong>: 当 DM 中每个 DDL 都出现时，将在<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L1101-L1142" target="_blank" rel="noreferrer">func handleJob</a>处触发刷新操作。<br> b. <strong>暂停/停止同步(由 <code>s.flushJobs</code> 驱动)</strong>: 在退出前刷新所有作业，在 <a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L1870" target="_blank" rel="noreferrer">func s.flushJobs()</a>中，每当遇到该场景，新的 flushJob 就会生成。或者使用<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L2174-L2203" target="_blank" rel="noreferrer">skip-error方法</a> 解决错误或中断的 DM 同步时，也会刷新。<br> c. <strong>IsFreshTask返回true</strong>: 如果streamController成功启动或Mode配置为 <code>ALL</code>，则从转储元文件加载的检查点将被刷新。<br> d. <strong>心跳事件收到</strong>: 在 <a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L1030" target="_blank" rel="noreferrer">func flushifexpired</a>，当每个事件从MySQL Binlog被分派到DML作业队列，<a href="https://github.com/pingcap/tiflow/blob/c65e2b72198de10319008b31dcf13d51509ccfde/dm/syncer/syncer.go#L2614" target="_blank" rel="noreferrer">这里</a>。</p></li><li><p>简而言之，检查点是保证数据复制过程中最终一致性的重要一项。我的意思是，如果出现任何错误，DM 可以在从错误中恢复后继续复制。</p></li></ol>',21)]))}const m=o(n,[["render",l]]);export{g as __pageData,m as default};
