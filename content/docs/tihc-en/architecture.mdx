---
title: Architecture
description: How the extension UI, serverless backend, GraphRAG, and evaluation fit together
---

## Components

- **Extension UI (`tihc`)**
  - Interaction layer and streaming output UI
  - Google login (token acquisition)
  - Forwards requests to serverless by default (local WebLLM as fallback)

- **Serverless (`tihc-serverless`)**
  - Single API endpoint: `POST /api/stream_chat`
  - Selects execution path via `chat_engine`:
    - `openai`: OpenAI streaming → plain text stream
    - `openai_rag`: GraphRAG retrieval → OpenAI answer
    - `manus`: proxy to Manus API
    - `tidb`: proxy to the TiDB-doc GraphRAG upstream
  - Google tokeninfo validation + Workspace domain enforcement (`GOOGLE_WORKSPACE_DOMAIN`)

- **Evaluation (`evalite-demo`)**
  - Gold set: supervised evaluation for “intake convergence”
  - Traces: analysis on real requests (can be unlabeled)

## Data & Privacy

Stateless by default: serverless only does “request → tools/models → streaming response”.

If you need access control / auditing / evaluation collection, store only the minimum necessary fields:

- User identifier (hashed), timestamp, engine, token counts, latency
- Do not store raw prompts/conversations (or anonymize first)
