


## TiDB HTAP Feature

### 行列混合模式
列存会基于**主键**实施更新

### TiDB-server作为数据入口
CBO或通过系统变量强制指定

### 与 TiKV 相同的sharding策略
同步变化的 replica unit of region from tikv

TiFlash 和 TiKV 唯一的区别就是不参与投票

### MPP  architecture
列存切分以列存模式
函数不完全相同（TiKV）

![01_architecture_tiflash](./TiFlash/01_architecture_tiflash.jpg)

TiFlash 特别适合仅查询几列的 SQL 场景


TiFlash 列存的存储方式，也是列存一般的解决方式为，先将 TiKV 行存数据按数量分组（如：1 百万行），再将行存分组结果按列分组，实现列存的存放。



## MPP 模式

MPP 其实

什么适合 MPP 模式去做，如一张表 50 行数据，另一张表取 100 行数据，再取 join 集的 SQL 场景是不适合 MPP ，可能造成单机 MySQL 比 MPP DB 更快的现象。    

MPP 适合计算结果过程中，总计算量非常打的情况，包含即使最后取出结果集非常小，但中间过程需要计算量很大的情况。    



TiFlash 能否实现 TiKV 、TiFlash 混合下推查询？

暂时不能，一但支持此种模式，TiFlash 需要同步支持 TiKV 所有下推函数，一旦 TIKV 有任何变化均要得到 TiFlash 同步支持，维护成本极高。

对应场景： TIDB 接到一个两表 join SQL,一张用户信息表从 TiKV 获取，一张大数据量宽表从 TiFlash 查询，TiFLash 需要 TiKV 中数据才能完成完整的下推计算。该 SQL 计算场景暂时不支持，**目前**想要将 SQL 中全部函数 下推存储引擎完成（TiFlash），完成某下推函数（如：case when）的所有数据均需存储在 TiFlash。    


TiFlash MPP 两大问题：

1. 缺算子
2. 大压力下写入 TiFlash 很难及时跟得上 TIKV 更新速度   

## TiFlash 最大优势

AP 与 TP 完全隔离



## TiFlash 两副本优势   

数据更均匀  


## 列存和行存不一定哪个快  

## 分区表对 TiFlash 的影响 


单纯的扫表和过滤数据并没有什么优势，优势时 join 的下推

