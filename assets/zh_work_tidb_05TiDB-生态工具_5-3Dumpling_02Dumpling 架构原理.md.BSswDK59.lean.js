import{_ as s,c as a,a4 as e,o as t}from"./chunks/framework.C3yiUNUH.js";const c=JSON.parse('{"title":"Dumpling 架构原理","description":"","frontmatter":{},"headers":[],"relativePath":"zh/work/tidb/05TiDB-生态工具/5-3Dumpling/02Dumpling 架构原理.md","filePath":"zh/work/tidb/05TiDB-生态工具/5-3Dumpling/02Dumpling 架构原理.md"}'),n={name:"zh/work/tidb/05TiDB-生态工具/5-3Dumpling/02Dumpling 架构原理.md"};function l(p,i,r,h,o,d){return t(),a("div",null,i[0]||(i[0]=[e(`<h1 id="dumpling-架构原理" tabindex="-1">Dumpling 架构原理 <a class="header-anchor" href="#dumpling-架构原理" aria-label="Permalink to &quot;Dumpling 架构原理&quot;">​</a></h1><h2 id="基本信息" tabindex="-1">基本信息 <a class="header-anchor" href="#基本信息" aria-label="Permalink to &quot;基本信息&quot;">​</a></h2><ol><li><p>仓库：最初，Dumpling 是一个单独的项目，但现在已合并到 <a href="https://github.com/pingcap/tidb/tree/master/dumpling" target="_blank" rel="noreferrer">TiDB Repo</a> 中。</p></li><li><p>分析：我必须说，Dumpling 是如此简单，但在大多数情况下，TiDB 集群通常会出现问题。尽管所有工具都有这种问题，但在我看来，Dumpling 更多。</p></li><li><p>工作原理：简而言之，Dumpling 并行连接 TiDB 集群，使用 SQL 并发地获取结果，并最终将结果写入 Linux 文件。</p></li></ol><h2 id="如何初始化" tabindex="-1">如何初始化 <a class="header-anchor" href="#如何初始化" aria-label="Permalink to &quot;如何初始化&quot;">​</a></h2><ol><li><p><a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L124-L137" target="_blank" rel="noreferrer">Startup steps</a> 是以下一系列步骤的集合：</p><div class="language-go vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">go</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">err </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> runSteps</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(d,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">initLogger,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">createExternalStore,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">startHTTPService,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">openSQLDB,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">detectServerInfo,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">resolveAutoConsistency,</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">validateResolveAutoConsistency,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tidbSetPDClientForGC,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tidbGetSnapshot,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tidbStartGCSavepointUpdateService,</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">setSessionParam)</span></span></code></pre></div></li><li><p>我将只关注主要步骤和组件，即 (createExternalStore, startHTTPServer, openSQLDB, resolveAutoConsistency, validateResolveAutoConsistency, tidbSetPDClientForGC, tidbStartGCSavepointUpdateService)，而其他部分只是协调器部分。对于 <code>createExternalStore</code>，由于 dumpling 已经提供了 Local、Hdfs、S3、Azure，因此它们具有完全不同的配置项，主要思想是获取足够的信息以进行 读/写 到不同的 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/br/pkg/storage/local.go#L161" target="_blank" rel="noreferrer">LocalStorage</a>。 <strong>我只关注 <code>Local</code>，它也是其他 externalStorage 背后实现逻辑的基础。</strong> 只是一个封装了导出路径的结构体。</p></li><li><p>对于 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/http_handler.go#L21" target="_blank" rel="noreferrer"><code>startHTTPServer</code></a>，在一个单独的 goroutine 中，它用于构建与度量相关的内容和内部调试，这在 Dumpling 二进制文件出现问题时进行调查非常有用。对于 [<code>openSQLDB</code>]，它只是初始化了一个连接到旨在导出数据的数据库。</p></li><li><p>对于 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L1429" target="_blank" rel="noreferrer">validateResolveAutoConsistency</a>，检查是否存在一种情况，即在 --consistency 不是快照时无法指定 --snapshot。</p></li><li><p>对于 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L1438" target="_blank" rel="noreferrer">tidbSetPDClientForGC</a>，如果下游是 TiDB，则必须设置 GC，但在此步骤中，只需初始化并准备足够的信息，以使 pd-client 在 Dumpling 中与 PD 通信。</p></li><li><p>对于 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L1466" target="_blank" rel="noreferrer">tidbGetSnapshot</a>，只需使用 <code>show master status</code> 获取 Position，如下所示，实际上与 tidb 中的 <code>select tidb_current_tso()</code> 相同；</p><div class="language-sql vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sql</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mysql</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> begin</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Query OK, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> rows</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> affected (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">00</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sec)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mysql</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Show </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">Master</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> Status</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">-------------+--------------------+--------------+------------------+-------------------+</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">| </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">File</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        | Position           | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">-------------+--------------------+--------------+------------------+-------------------+</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">| tidb</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">binlog | </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">441037036439732234</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> |              |                  |                   |</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">-------------+--------------------+--------------+------------------+-------------------+</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> row</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> in</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> set</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sec)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mysql</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> select</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tidb_current_tso();</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">--------------------+</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">| tidb_current_tso() |</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">--------------------+</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">| </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">441037036439732234</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> |</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">--------------------+</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> row</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> in</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> set</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sec)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mysql</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> commit</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Query OK, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> rows</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> affected (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sec)</span></span></code></pre></div></li><li><p>对于 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L1497" target="_blank" rel="noreferrer">tidbStartGCSavepointUpdateService</a> ，它使用从 <code>tidbGetSnapshot</code> 获得的快照来设置 <a href="https://github.com/pingcap/dumpling/issues/95" target="_blank" rel="noreferrer">TiKV GC safepoint</a>，并设置了一个 ttl。因此，通过这种方式，更高版本的 Dumpling 可以防止 TiKV GC 正在使用的要导出的数据。</p></li><li><p>对于 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L1559" target="_blank" rel="noreferrer">setSessionParam</a>，由于支持以 <code>dumpling --params</code> 方式使用的额外会话变量。不得不说，这种方式与 TiDB 交互非常重要，因为我在页面顶部提到在导出数据时， <strong><code>TiDB 集群通常会出现问题</code></strong>。</p></li></ol><h2 id="如何工作" tabindex="-1">如何工作 <a class="header-anchor" href="#如何工作" aria-label="Permalink to &quot;如何工作&quot;">​</a></h2><ol><li><p>在初始化步骤之后，<a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L143" target="_blank" rel="noreferrer">Dump()</a> 是从数据库中导出表的主要逻辑。</p></li><li><p>在 Dump() 中，有一个逻辑选择通过 SQL 还是通过数据库导出，这取决于您是否配置了 <code>--sql</code> 参数。</p></li><li><p><a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L267" target="_blank" rel="noreferrer">func startWrite</a> 将创建与 <code>Threads</code> 数量相同的 groutines。创建的 groutines 用于并行处理任务。从 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/writer.go#L102" target="_blank" rel="noreferrer">func Write.handleTask</a> 的逻辑来看，有一系列函数，如 <code>WriteDatabaseMeta</code>、<code>WriteTableMeta</code>、<code>WriteTableData</code> 等。这些函数主要是执行 SQL 查询并将结果写入不同的 externalStorage 文件。</p></li></ol><h2 id="sql-导出" tabindex="-1">SQL 导出 <a class="header-anchor" href="#sql-导出" aria-label="Permalink to &quot;SQL 导出&quot;">​</a></h2><ol><li><p>在 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L1261" target="_blank" rel="noreferrer">detectEstimateRows</a> 函数中，使用 <code>fmt.Sprintf(&quot;EXPLAIN %s&quot;, &quot;select * from table_a a left join table_b b on a.id = b.id where ...&quot;)</code> 来获取 estimateRows，但是它只是用来记录 dumpling_dump_estimate_total_rows 指标的值。到目前为止，还没有任何关于 Dumpling 的开源服务。我猜在未来会有一个 <a href="https://github.com/pingcap/tidb/issues/34948" target="_blank" rel="noreferrer">Dataflow Engine</a> 作为后端服务运行 Dumpling。</p></li><li><p>正如我上面提到的，Writer 组件将执行查询并将结果保存为文件。值得注意的是，使用 Dumpling 的 <code>--sql</code> 的逻辑是通过 <code>totalChunks</code> 硬编码为 <code>1</code> 来执行查询的唯一方式，也就是说不存在并发。</p></li></ol><h2 id="schema-导出" tabindex="-1">Schema 导出 <a class="header-anchor" href="#schema-导出" aria-label="Permalink to &quot;Schema 导出&quot;">​</a></h2><ol><li><p>首先，有<a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L420-L484" target="_blank" rel="noreferrer">很多循环</a>来准备每个表模式和表数据作为任务并将它们发送到 Write 等待处理。</p></li><li><p>在 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L624-L627" target="_blank" rel="noreferrer">func dumpTableData</a> 内部有一个主要的逻辑来调整是否使用并发。如果您配置了 <code>--rows</code>，则会使用并发。如果没有，则整个表将使用一个查询导出结果，例如 <code>select column_a，column_b，column_c ... from database_a.table_a order by XXX</code>。但是，并发方式首先是 <a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/dump.go#L731" target="_blank" rel="noreferrer">the func concurrentDumpTable</a> 尝试将表拆分为多个块以进行导出。</p></li><li><p>单表导出通过以下步骤并发执行：<br> a. 首先，<a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/sql.go#L439" target="_blank" rel="noreferrer">func orderByClause</a> 决定使用 <code>_tidb_rowid</code> 或 <code>Primary key</code> 进行排序。<br> b. 其次，[func pickupPossibleField] 决定使用 <code>_tidb_rowid</code> 或 <code>Numeric PK</code> 或 <code>UK Index</code> 或 <code>no proper index</code>，按我编写的顺序优先。<br> c. 第三，<a href="https://github.com/pingcap/tidb/blob/eb35c773b512e4e00c42caf7f04ea7397d00c127/dumpling/export/sql.go#L1175" target="_blank" rel="noreferrer">func estimateCount</a> 使用 <code>EXPLAIN SELECT * FROM DATABASE_XXX.TABLE_XXX</code> 获取估计的 RowNumber。<br> d. 如果 estimateCount &lt; <code>--rows</code>，则直接使用一个单一的 sql 导出表。<br> e. 如果 pickupPossibleField 可以输出合适的字段（单数或复数），则使用 <code>SELECT MIN(field_xxx),MAX(field_xxx) FROM database_a.table_a</code> 获取最大值和最小值。如果有任何错误或无法获取最大值或最小值，则直接使用一个 sql 导出表。<br> f. 然后，使用 <code>estimatedChunks := count / conf.Rows</code> 将其拆分为一些块，并将它们并行执行为任务。</p></li></ol><h2 id="最后总结" tabindex="-1">最后总结 <a class="header-anchor" href="#最后总结" aria-label="Permalink to &quot;最后总结&quot;">​</a></h2><p>在快速查看源代码后，我们了解到以下内容：</p><ol><li><code>--row</code> 是控制表格是否可以被分成不同的块并并行执行的开关。</li><li><code>--thread</code> 是控制不同表格之间并发的开关。</li><li>尽管我们已经配置了 <code>--rows</code>，但有些情况下，因为无法将分割 chunk 导致表内部的数据导出无法以并发的方式执行。</li></ol>`,14)]))}const g=s(n,[["render",l]]);export{c as __pageData,g as default};
