# 日常监控与告警处理手册




二、TiDB 指标监控与告警总体架构	3
三、监控告警组件运维	4
1. 监控告警架构	4
2. 组件配置说明	5
3. 监控告警组件运维	7
四、重要监控项说明	8
1. PD 监控项说明	8
2. TiDB 监控项说明	9
3. TiKV 监控项说明	10








一、前言
本手册为 TiDB 告警系统配置和管理手册
二、TiDB 指标监控与告警总体架构

TiDB 使用开源时序数据库 Prometheus 作为监控和性能指标信息存储方案，使用 Grafana 作为可视化组件进行展示。
Prometheus 是一个拥有多维度数据模型，灵活的查询语句的时序数据库。Prometheus 作为热门的开源项目，拥有活跃的社区及众多的成功案例。
Prometheus 提供了多个组件供用户使用。目前，我们使用 Prometheus Server，来收集和存储时间序列数据。Client 代码库，在程序中定制需要的 Metric 。Push GateWay 来接收 Client Push 上来的数据，统一供 Prometheus 主服务器抓取。以及 AlertManager 来实现报警机制。
三、监控告警组件运维
1. 监控告警架构
整个架构如下图所示，在 TiDB/PD/TiKV 三个组件的启动参数中添加 Prometheus Pushgateway 地址:

监控系统
Prometheus Push Gateway 参考： https://github.com/prometheus/pushgateway
Prometheus Server 参考： https://github.com/prometheus/prometheus#install
Grafana 参考： http://docs.grafana.org
告警系统
主路告警：收集 TiDB Cluster 主动上报的数据，分析，产生告警。
旁路告警：对主路监控的补充，一方面检测主路报警的模块是否正常，另一方面也会直接监控 TiDB 的关键服务工作状态，针对异常产生告警。

告警流程 - 主路监控
TiDB Cluster 组件运行过程中，上报程序状态（metric）到 Prometheus。
Prometheus 收集所有的 metrics。
在 Prometheus 配置文件配置告警规则（后续介绍），Prometheus 根据规则判断上报的 metric 信息是否异常，异常产生告警信息，推送到 Alertmanger。
Alertmanger 将告警信息推送的 Slack、SMS、Email 等告警渠道。
告警流程 - 旁路监控 (ByPass Monitoring) 
旁路监控负责检测重要的系统服务是否正常，同时检查主路监控是否正常，即监控的监控。
实时上报监控信息给 Prometheus，同时上报心跳，用于存档和统计。
检测到重要服务发生异常，直接推送告警信息到 Alertmanger。
2. 组件配置说明
TiDB
设置 --metrics-addr 和 --metrics-interval 两个参数，其中 --metrics-addr 为 Push Gateway 的地址，--metrics-interval 为数据推送的频率，单位为秒，默认值为 15。
PD
修改 toml 配置文件，填写 Push Gateway 的地址和推送频率。
          [metric]
# prometheus client push interval, set "0s" to disable prometheus.
interval = "15s"
# prometheus pushgateway address, leaves it empty will disable prometheus.
address = "host:port"
TiKV
修改 toml 配置文件，填写 Push Gateway 的地址和推送频率，job 字段一般设置为“tikv”。
          [metric]
# the Prometheus client push interval. Setting the value to 0s stops Prometheus client from pushing.
interval = "15s"
# the Prometheus pushgateway address. Leaving it empty stops Prometheus client from pushing.
address = "host:port"
# the Prometheus client push job name. Note: A node id will automatically append, e.g., "tikv_1".
job = "tikv"
PushServer 配置
一般无需特殊配置，使用默认端口 9091 即可。
Prometheus 配置
发送到 Alertmanger 配置
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - '127.0.0.1:39093’ --- Alertmanger的地址
告警规则配置
rule_files:
  - 'node.rules.yml'     # host告警规则
  - 'blacker.rules.yml'  # 网络告警规则
  - 'bypass.rules.yml'  # 旁路监控规则
  - 'pd.rules.yml'         # pd告警规则
  - 'tidb.rules.yml'       # tidb告警规则
  - 'tikv.rules.yml'        # tikv告警规则
  - 'binlog.rules.yml'   # binlog告警规则
Grafana 配置
进入 Grafana Web 界面（默认地址: http://grafana_host_ip:3000 ，默认账号: admin 密码: admin）；
点击 Grafana Logo -> 点击 Data Sources -> 点击 Add data source -> 填写 data source 信息 ( 注: Type 选 Prometheus，Url 为 Prometheus 地址，其他根据实际情况填写 ）；
导入 dashboard 配置文件；
点击 Grafana Logo -> 点击 Dashboards -> 点击 Import -> 选择需要的 Dashboard 配置文件上传 -> 选择对应的 data source。
Alertmanager 配置
路由配置
route:
  receiver: "alerts"  
  group_by: ['env','instance','type','group','job']
  group_wait:      30s
  group_interval:  3m
  repeat_interval: 3m
  routes:
  - match:
    continue: true
    receiver: ‘send-sms’  # webhook 的 receiver 配置
receiver 配置
- name: send-kafka  # 上述路由对应receiver
  webhook_configs:
  - send_resolved: true
    url: 'http://172.16.10.49:28082/v1/alertmanager'  # kafka adapter配置
验证 Alertmanager 是否正常
curl -H "Content-Type: application/json" -d '[{"labels":{"alertname":"TestAlert1"}}]' alertmanger_host:9093/api/v1/alerts
3. 监控告警组件运维
Prometheus
使用 ansible 启动 Prometheus
ansible-playbook start.yml -t prometheus
使用 ansible 关闭 Prometheus
	ansible-playbook stop.yml -t prometheus
使用ansible 升级 Prometheus
ansible-playbook rolling_update_monitor.yml -t prometheus
Alertmanager     
Alertmanager 手动启动命令
./alertmanger
--config.file="alertmanager.yml" \  # alertmanger配置文件
--storage.path="./data" \    # 数据存储目录
--data.retention=120h  \   #数据存储时效
--log.level=info \ #   日志级别
--web.listen-address=":9093"  #   web访问端口
Alertmanager 启动
ansible-playbook start.yml -t alertmanager
Alertmanager 停止
ansible-playbook stop.yml -t  alertmanager
Alertmanager 更新
ansible-playbook rolling_update_monitor.yml -t  alertmanager
旁路告警
手动启动方式
./bin/tidb_exporter  
-pd-list "http://10.1.0.4:2379,http://10.1.0.5:2379,http://10.1.0.6:2379" # PD信息
-tidb-list "10.1.0.4:4000,10.1.0.5:4000,10.1.0.6:4000"  # TiDB信息
-metrics 10.1.0.4:9091   # Prometheus信息
-daemon  # daemon启动
ansible启动方式
ansible-playbook start.yml -t exporter
旁路告警停止
ansible-playbook stop.yml -t  exporter
旁路告警更新
ansible-playbook rolling_update_monitor.yml -t  exporter
四、重要监控项说明
1. PD 监控项说明
Storage Capacity：TiDB 集群总可用数据库空间大小。
Current Storage Size：TiDB 集群目前已用数据库空间大小。
Store Status - up store：TiKV 正常节点数量，一个 store 即为一个 TiKV 实例。
Store Status – down store：TiKV 异常节点数量，如果大于 0，证明有节点不正常。
Store Status – offline store：手动执行下线操作 TiKV 节点数量。
Store Status – Tombstone store：下线成功的 TiKV 节点数量。
Current storage usage：TiKV 集群存储空间占用率，超过 80% 应考虑添加 TiKV 节点。
Current Regions Count：当前 region 数量（只计算单一副本）。
99% completed_cmds_duration_seconds：99% pd-server 请求完成时间，一般小于 5ms。
average completed_cmds_duration_seconds：pd-server 请求平均完成时间，一般小于 50ms。
leader balance ratio：leader ratio 最大的节点与最小的节点的差，均衡状况下一般小于 5%，节点重启时会比较大。配置了 leader 调度权重则不需要关注此项。
region balance ratio：region ratio 最大的节点与最小的节点的差，均衡状况下一般小于 5%，新增/下线节点时会比较大。配置了 region 调度权重则不需关注此项。
Scheduler limit：region 调度的速度。
hot write/read region's leader/peer distribution：写/读热点 region leader 的分布。
handle_txns_count：单位时间内 PD 通信的数量。
average handle_txns_cmds_duration_seconds：PD 通信平均消耗的时间。
average walf_sync_duration_seconds：wal 日志刷磁盘平均消耗的时间。
handle_requests_count：单位时间内l来自于 tidb-server 请求的数量。
handle_requests_duration_seconds：TiDB 发出各类请求命令到 PD 响应的时间。
region heartbeat：单位时间内 PD 收到 region 心跳的数量。
2. TiDB 监控项说明
handle_requests_duration_seconds：请求 PD 获取 TSO 响应时间，一般小于 100ms。
QPS：各 tidb-server 的 QPS。
QPS Total：集群 QPS 总量。
connection count：数据库上的连接数，和业务相关，但是如果连接数发生跳变，需要查明原因，突然掉为 0，可以检查网络是否中断；突然上涨，需要检查业务。
statement count：单位时间内不同类型语句执行的数目。
Heap Memory Usage：各个 tidb-server 使用内存的大小。
Average Query Duration：平均查询延迟。
Query Duration 99th percentile：第 99 个百分位的 query 执行时间。
KV Cmd Count：单位时间内 kv 不同操作的数量。
KV Retry Seconds 9999：kv 重试的时间（99.99%）如果没有写入冲突的话，一般为 0。
KV Request Seconds 9999：tidb-server 执行操作后 TiKV 的响应时间（99.99%）。
KV Cmd Seconds 99：kv 不同操作消耗的时间（99%）。
TiClient Region Error：一些 TiKV 相关的错误信息（not_leader 等），数量不多属于正常现象。
LockResovle：锁与解锁的数量。
KV Backoff Count：事务冲突、region miss 等相关的监控。
3. TiKV 监控项说明
99% & 99.99% scheduler command duration：99% & 99.99% 命令执行的时间，一般 99% 小于 50ms；99.99% 小于100ms。
95% & 99% storage async_request duration：95% & 99% Raft 命令执行时间，一般 95% 小于 50ms；99% 小于100ms。
server report failure message：发送失败或者收到了错误的 message，如果出现了大量的 unreachadble 的消息，表明系统网络出现了问题。如果有 store not match 这样的错误，表明收到了不属于这个集群发过来的消息。
Vote：Raft vote 的频率，通常这个值只会在发生 split 的时候有变动，如果长时间出现了 vote 偏高的情况，证明系统出现了严重的问题，有一些节点无法工作了。
95% & 99% coprocessor request duration：95% & 99%  coprocessor 执行时间，和业务相关，但通常不会出现持续高位的值。
Pending task：累积的任务数量，除了 pd worker，其他任何偏高都属于异常。
stall：RocksDB Stall 时间，大于 0，表明 RocksDB 忙不过来，需要注意 IO 和 CPU 了。
channel full：channel 满了，表明线程太忙无法处理，如果大于 0，表明线程已经没法处理了。正常情况下没有数据。
95% send_message_duration_seconds：95% 发送消息的时间，一般小于50ms。
leader/region：每个 TiKV 的 leader/region 数量，和业务相关。
cf size：数据在 cf 中的存储情况。
store size：TiKV 实例存储的数据量。
server report failures：TiKV 之间的通信状况，为 0 说明通信良好。有监控值一般有 channel full 或者网络卡顿。
scheduler pending commands：监控值太高表示写入繁忙。
coprocessor table/index request/wait/handle duration：查询相关的监控，如果监控值太大，会影响 tidb-server 查询速度。
coprocessor pending requests：监控数值太高表示查询繁忙。
Worker Pending Tasks：根据监控可以判断 TiKV 哪些线程有任务堆积。
raft store CPU：raftstore 是 TiKV 之间通信使用的线程，线程 cpu 使用率过高会导致 channel full。
async apply CPU、scheduler CPU：写入相关的线程使用 cpu 的状况，一般不会很高。
coprocessor CPU：查询相关的线程使用 cpu 的状况，假如有复杂查询，cpu 使用率会比较高。




版本
版本
修改时间
修改人
修改内容
v1.0
2018-07-25
修改记录
第一次建立文档

